



**分时调度：**
轮流使用cpu使用权，平均分配每个线程占用cpu的时间；

**抢占式调度：**
优先级较高的使用cpu，如果线程优先级相同，随机选择一个，**java使用的为抢占式调度**。



**主线程** ：执行主方法（main）的线程。JVM执行main方法会进入栈内存中，jvm会找操作系统开辟一条main方法通向cpu的执行路径，cpu就可以通过路径来执行main方法。

继承Thread类，重写run方法：

```java
class Son extends Dad {
   	String nickName;
   	Son(String nickName){
   		this.nickName = nickName;
   	}
   	public void run() {
   		//TODO
   	}
}
```

创建并启动一个线程：

```java
Son s = new Son("大头");
s.start();
```

调用start方法，开启新的线程，执行run方法。结果是两个线程并行。多次start一个线程是非法的，特别是当线程结束运行后，不能再重新启动。


对于CPU而言，多线程意味着有多条执行路径，意味着CPU有选择权

main方法压栈执行

![1571077848674](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1571077848674.png)




两种创建方法
1.继承Thread类，重写run方法
启动直接调用start()方法
2.实现Runnable接口，实现run方法
Person p = new Person();
new Thread(p).start();

1.避免了单继承的局限性
2.增强程序的扩展性，降低了程序的耦合性，把设置线程任务和开启新线程进行了分离



匿名内部类实现线程的创建
匿名：没有名字
内部类：卸载其它类内部的类

作用：简化代码
```java
new Thread(){
	@Override
	public void run(){
		System.out.println("");
	}
}.start();
```

```java
new Thread(new Runnable() {
	@Override
	public void run() {
		System.out.println("");
	}
}).start();
```



同步的方法

1.同步代码块

2.同步方法

3.锁机制

同步代码块：用在方法某个区块中，对区块的资源进行互斥访问


```java
synchronized(锁对象) {
	需要同步操作的代码（访问了共享数据的代码）
}
```

--锁对象可以使用任意对象

--必须保证多个线程使用的锁对象是同一个

--锁对象的作用是把代码块锁住，只让一个线程在同步代码块中执行

同步锁：







## 第二章 并发机制的底层实现原理

### 2.1 volatile的应用

官方定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。

修饰变量，每个线程看到的值都是一样的，成本低，不会引起线程上下文切换

volatile修饰>>>写操作时会多出第二行代码0x01a3de24: lock addl $0 x 0, (%esp);>>>lock会引起处理器缓存写回主内存>>>缓存写回主内存会导致其它处理器同一个数据缓存失效>>>其它处理器操作此数据时要从主内存中读取



处理器如何保证单个CPU缓存和主内存数据一致？

单个处理器通过嗅探主内存，主内存中数据发生修改，单个处理器把自身缓存中的这个数据设为无效。

在新处理器中lock一般不锁总线，锁缓存，并写回主内存，使用缓存一致性来保证原子性，成为“缓存锁定”，缓存一致性会制止同时修改两个或以上处理器缓存的内存区域数据。



### 2.2 synchronized实现原理与应用



**锁住了什么？**

1.对于普通方法，锁住当前实例对象；

2.对于静态同步方法，锁住当前类的Class对象；

3.对于同步方法块，锁的是Synchronized括号里配置的对象。

**怎么锁？**

1.任何对象都有一个monitor对象；

2.对于同步代码块，在编译时，在同步代码块开始位置插入monitorenter，在方法结束处和异常位置插入monitorexit，jvm会保证enter和exit配对；

3.与对象关联的monitor被持有后，它将处于锁定状态。



#### 2.2.1 对象头

synchronized用的锁是存放在Java对象头里的。



非数组对象32/64位：

| 长度        | 内容                   | 说明                         |
| ----------- | ---------------------- | ---------------------------- |
| 32bit/64bit | Mark Word              | 存储对象的hashCode或者锁信息 |
| 32bit/64bit | Class Metadata Address | 存储到对象类型数据的指针     |

数组对象32/64位：

| 长度        | 内容                   | 说明                         |
| ----------- | ---------------------- | ---------------------------- |
| 32bit/64bit | Mark Work              | 存储对象的hashCode或者锁信息 |
| 32bit/64bit | Class Metadata Address | 存储到对象类型数据的指针     |
| 32bit/64bit | Array length           | 存储数组长度                 |



#### 2.2.2 锁的升级与对比

锁有四种状态（SE1.6）：无锁状态、偏向锁状态、轻量级锁、重量级锁

锁级别能升不能讲

| 锁       | 优点                          | 缺点                               | 适用场景                     |
| -------- | ----------------------------- | ---------------------------------- | ---------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗    | 线程间锁竞争会带来额外锁撤销的消耗 | 单线程同步块                 |
| 轻量级锁 | 竞争线程不会阻塞，响应快      | 等不到锁的线程会自旋消耗CPU        | 求响应快，同步块响应速度快   |
| 重量级锁 | 线程竞争不会自旋，不会消耗CPU | 线程阻塞，响应慢                   | 求吞吐量大，同步块响应速度慢 |



**偏向锁：**

偏向锁获取：当一个线程访问同步块获取锁时，会在对象头和栈帧的锁记录中，存放其偏向的线程ID，以后该线程退出或进入同步块时不需要进行CAS来加锁和解锁，只需简单测试对象头的mark word里是否存储着指向当前线程的偏向锁；

偏向锁撤销：等到竞争出现才释放；

关闭偏向锁：JVM参数-XX:-UseBiasedLocking=false，程序默认进入轻量级锁  





### 2.3 原子操作的实现原理

#### 2.3.2 处理器如何实现原子操作

处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

**总线锁定**

提供一个LOCK #信号，当一个处理器在总线上输出此信号时，其它处理器的请求被阻塞，该处理器独占共享内存。



**缓存锁定**

在某一个时刻，保证对某个内存地址的的操作是原子性，缓存一致性协议会阻止同时修改两个以上处理器缓存的内存区域数据。写回主内存存时，不在总线上声言LOCK#信号，而是修改内部的内存地址。



**什么情况不能使用缓存锁定？**

1.处理器不支持；

2.当操作的数据不能缓存在处理器内部，或者操作的数据跨多个缓存行（cache line是缓存的最小操作单位）。

**开销：**锁总线>锁缓存（总线锁定会把CPU和总线的通信锁住）



#### 2.3.3 java如何实现原子操作

使用锁或循环CAS。

**使用锁：**JVM内部实现了很多种锁机制，除了偏向锁，其它锁都使用了循环CAS来获取和释放锁。

**循环CAS：**

```java
/**使用CAS实现线程安全计数器**/
private AtomicInteger atomicI = new AtomicInteger(0);
private void safeCount() {
    for (;;) {
        int i = atomicI.get();
        boolean suc = atomicI.compareAndSet(i, ++i);
        if (suc) {
            break;
        }
    }
}

/**非线程安全**/
private int i = 0;
public void count() {
    count++;
}
```

**CAS实现原子操作的三大问题**

1.ABA问题

2.循环时间开销大

3.只能保证一个共享变量的原子操作



## 第三章 Java内存模型

### 3.1 Java内存模型的基础

#### 3.1.1 并发编程模型的两个关键问题

线程之间如何通信？

线程之间如何同步？



在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。



并发共享内存模型：读取共享内存，隐式通信；(Java采用/)

并发消息传递模型：发消息，显示通信。



#### 3.1.3 从源代码到指令序列的重排序

从源码到最终指令序列经历3种排序：

1.编译器优化重排序；（不改变单线程语义的前提下）

2.指令级并行重排序；（现代处理器采用指令集并行技术，将多条指令重叠执行）

3.内存系统重排序。（处理器使用缓存和读写缓冲区）



#### 3.1.4 并发编程模型的分类

 

**背景：**现代处理器的写缓冲区会临时保存向内存写入的数据，以批处理的方式刷新主内存，以及合并对同一地址的多次写，减少对内存总线的占用。现代处理器都使用写缓冲区，允许写-读进行重排序。

**引发问题：**这种批量/合并写仅对它所在的处理器可见（**引出内存可见性**），其它处理器不知道合并刷新。导致处理器对内存的读写顺序，不一定与实际执行顺序一致。



为了保证内存可见性，适当插入内存 ，禁止处理器指令重排序



#### 3.1.5 happens-before规则简介

​	JDK5开始使用JSR-133，在JMM中，如果一个操作需要对另一个操作可见，那么这两个操作之间必须存在 happens-before关系。

​	happens-before指的是执行结果可见，不是前个操作必须要在后操作之前执行。

​	与程序员密切相关的happens-before规则：

- 程序顺序规则：线程中每个操作，happens-before与线程中的任意后续操作；
- 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁；
- volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读；
- 传递性：A h-b B 且B h-b C，则A h-b C。

### 3.2 重排序

​	重排序是指**编译器和处理器**为了**优化程序性能**对**指令序列进行重新排序**的行为



#### 3.2.1 数据依赖性

​	两操作访问同一变量，其中一操作为写，这两个操作存在数据依赖性。

​	编译器和处理器重排序时会遵守数据依赖性，不改变其依赖顺序。仅对单线程、单个处理器而言。

#### 3.2.2 as-if-serial语义

​	as-if-serial是指不管怎么重排序，（单线程）执行结果不变。

#### 3.2.3 程序顺序规则

​	计算机软硬件有一个共同目标：在不改变程序执行结果的前提现下，尽可能提供并行度。



### 3.3 顺序一致性

​	是一个理论模型。处理器内存模型和编程语言的内存模型都会**以顺序一致性模型作为参照**。

#### 3.3.1 数据竞争与数据一致性

​	Java对数据竞争定义：一个线程写同一个变量，一个线程读同一个变量，而且写和读没有同步来排序。（这里的同步指的是广义上同步，包括对常用同步原语synchronized、volatile和final的正确使用）	

#### 3.3.2 顺序一致性内存模型

​	**两大特性：**

- ​	一个线程必须程序的顺序来执行；

- ​	所有线程只能看到单一的操作执行顺序，每个操作原子执行且对所有线程可见。

  通俗讲，把所有线程读写操作**串行化**。

注意：JMM中未同步的程序执行顺序是无序的，所有线程看到的操作执行顺序也可能不一致。



   ### 3.4 volatile的内存语义

#### 3.4.1 volatile的特性

​	用来做同步。

​	**volatile变量两个特性：**

- ​	可见性（保证）：变量读写对所有线程可见；
- ​	原子性（不保证）：对单个vol atile变量的读/写具有原子性，但volatile++这种复合操作不具有原子性。 （++是又读又写）

##### 3.4.4 volatile内存语义试下

​	在编译器生成字节码时，插入内存屏障，禁止不同处理器重排序。

| 是否能重排序 | 第二个操作  | 第二个操作 | 第二个操作    |
| :----------: | ----------- | ---------- | :------------ |
|  第一个操作  | 普通读 / 写 | volatile读 | volatile写    |
| 普通读 / 写  |             |            | no（1）       |
|  volatile读  | no（3、4）  | no（3、4） | no（1、3、4） |
|  volatile写  |             | no（2）    | no（1、2）    |

​	**规律：**

- ​	第一个为volatile读时，不管第二个是什么，都不能重排序；
- ​	第二个为volatile写时，不管第一个是什么，都不能重排序；
- ​	第一个为volatile写，第二个为volatile读时，不能重排序。

​	**基于保守策略的JVM内存屏障插入：**

- ​	在每个**volatile写**操作的**前**面插入一个**StoreStore**屏障；
- ​	在每个**volatile写**操作的**后**面插入一个**StoreLoad**屏障；
- ​	在每个**volatile读**操作的**后**面插入一个**LoadLoad**屏障；
- ​	在每个**volatile读**操作的**后**面插入一个**LoadStore**屏障；

*注意：X86仅会对写-读操作重排序，省略三种内存屏障，JMM仅需在volatile写后面插入一个StoreLoad屏障即可确实现。意味着X86的volatile写比volatile读开销大很多。*



#### 3.4.5 JSR-133为什么要增强volatile的内存定义

| 对比项                       | 旧内存模型                   | JSR-133                    |
| ---------------------------- | ---------------------------- | -------------------------- |
| volatile写-读和锁的释放-获取 | 内存语义不同                 | 内存语义相同               |
| 保证原子性范围               | 仅保证单个volatile读写原子性 | 保证临界区代码执行有原子性 |

增强目的：提供一种比锁更轻量级的线程之间的通信。

增强内容：使**volatile写-读**和**锁的释放-获取**具有相同的内存语义。

在功能上，锁更强大；在可伸缩性上，volatile更有优势。



### 3.5 锁的内存含义



#### 3.5.1 锁的释放-获取建立的happens-before关系

​	锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息（通过主内存）。



#### 3.5.2 锁的释放与获取的内存含义

​	当线程释放锁，把线程对应的本地内存刷到主内存；

​	当线程获取锁，把线程对应的本地内存设置为无效；

​	被监视器保护的临界区代码必须从主内存中读取共享变量。



#### 3.5.3 锁的内存语义实现

​	AQS（AbstractQueuedSynchronized）;

​	CAS（compareAndSet）；

​	AQS使用**一个整型的volatile变量（命名为state）来维护同步状态**，这个变量是ReentrantLock内存语义实现的关键。

**共享变量：**A写state前可见的共享变量，在B获得锁读取同一个state后，对B可见。

ReentrantLock锁分公平和非公平；

|                                       | lock()和unlock()方法轨迹（ReentrantLock lock = new ReentrantLock()） |
| ------------------------------------- | ------------------------------------------------------------ |
| 公平锁获取锁lock.lock()               | ReentrantLock : lock()<br />FairSync : lock()<br />AbstractQueuedSynchronizer : acquire(int arg)<br />//第四步真正加锁<br />ReentranLock : tryAcquire(int acquires) |
| 非公平锁获取锁lock.lock()             | ReentrantLock : lock()<br />NonfairSync : lock()<br />//第三步真正加锁<br />AbstractQueuedSynchronizer : compareAndSetState(int expect,int update) |
| 公平与非公平锁<br />释放锁lock.lock() | ReentrantLock : unlock()<br />AbstractQueuedSynchronizer : release(int arg)<br />Sync : tryReleases(int releases) |

|          | 获取                                                         | 释放                            |
| -------- | ------------------------------------------------------------ | ------------------------------- |
| 公平锁   | 首先会去读volatile变量                                       | 最后都要写一个volatile变量state |
| 非公平锁 | 首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存含义 | 最后都要写一个volatile变量state |

锁释放-获取的内存语义的实现至少有下面两种方式：

- 利用volatile变量的写 - 读所具有的内存语义；
- 利用CAS所附带的volatile读和volatile写的内存含义。

JDK中说CAS同时具有volatile读和volatile写的内存含义。



#### 3.5.4 concurrent包的实现

​	Java的**CAS**会**使用**现代处理器上提供的**高效机器级别的原子指令**，这些指令以原子方式对内存执行读 - 改 - 写，这是多处理器实现同步的关键。现代处理器都会支持某种能对内存执行原子性读 - 改 - 写操作的原子指令。

**concurrent包**的源码实现有**一个通用的实现模式**：

- 首先声明共享变量为volatile；
- 使用CAS的原子条件更新来实现线程间的同步；
- 配合volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程间的通信。

![](C:\Users\Administrator\Pictures\markdown\并发编程的艺术\concurrent包实现示意图_看图王.png)



### 3.6 final域的内存语义

​	与锁和volatile相比，对final域的读和写更像是普通变量的访问。



#### 3.6.1 final域的重排序规则

​	对于final域，编译器和处理器要遵守两个重排序规则：

- ​	在构造函数内对一个final域写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序；
- ​	初次读一个包含final域的对象引用，与随后初次读这个final域，这两个操作之间不能重排序。



#### 3.6.2 写final域的重排序规则

​	**写final域的重排序规则禁止把final域的写重排序到构造函数之外**，包含两方面：

- ​	JMM禁止编译器把final域的写重排序到构造函数之外；
- ​	编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。

**确保：**在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域没有这个保障。



#### 3.6.3 读final域的重排序规则

​	在一个线程中，**初次读独享引用**与**初次读该对象包含的final域**，**JMM禁止处理器重排序这两个操作**（这个规则仅针对处理器），编译器会在读final域操作的前面插入一个LoadLoad屏障。

**确保**：对一个对象的final域之前，一定会先读包含这个final域的对象引用。